#Titanic Classification
#Logistic Regression with Python


#Import Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt;
import seaborn as sns
%matplotlib inline


from google.colab import drive
drive.mount('/content/drive/')


train = pd.read_csv("/content/drive/MyDrive/Datasets/Titanic classification/train.csv")

train.tail()

#Exploratory Data Analysis
#Missing Data
sns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='viridis')
train.isnull().sum().sort_values(ascending=False)

sns.set_style('whitegrid')
sns.countplot(x='Survived',data=train,palette='RdBu_r')

sns.set_style('whitegrid')
sns.countplot(x='Survived',hue='Sex',data=train,palette='RdBu_r')

sns.set_style('whitegrid')
sns.countplot(x='Survived',hue='Pclass',data=train,palette='rainbow')

train['Age'].hist(bins=30,color='darkred',alpha=0.7)

sns.countplot(x='SibSp',data=train)

sns.countplot(x='Parch',data=train)

train['Fare'].hist(color='green',bins=40,figsize=(8,4))

#Data Cleaning
plt.figure(figsize=(12, 7))
sns.boxplot(x='Pclass',y='Age',data=train,palette='winter')

def impute_age(cols):
    Age = cols[0]
    Pclass = cols[1]

    if pd.isnull(Age):

        if Pclass == 1:
            return 37

        elif Pclass == 2:
            return 29

        else:
            return 24

    else:
        return Age

train['Age'] = train[['Age','Pclass']].apply(impute_age,axis=1)

train['Embarked'] = train['Embarked'].fillna('S')

sns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='viridis')

train.drop('Cabin',axis=1,inplace=True)

train.head()

train.dropna(inplace=True)

train.info()

sex = pd.get_dummies(train['Sex'],drop_first=True)
embark = pd.get_dummies(train['Embarked'],drop_first=True)

train.drop(['Sex','Embarked','Name','Ticket'],axis=1,inplace=True)

train = pd.concat([train,sex,embark],axis=1)

train.head()

#Train Test Split
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(train.drop(['Survived'],axis=1),
                                                    train['Survived'], test_size=0.10,
                                                    random_state=101)

#Training and Predicting
from sklearn.linear_model import LogisticRegression

logmodel = LogisticRegression()
logmodel.fit(X_train,y_train)

predictions = logmodel.predict(X_test)
X_test.head()

predictions

#Evaluation
from sklearn.metrics import classification_report,confusion_matrix
print(confusion_matrix(y_test,predictions))
print(classification_report(y_test,predictions))


#Decision Tree Classifiction
from sklearn.tree import DecisionTreeClassifier
dt_model=DecisionTreeClassifier()
dt_model.fit(X_train,y_train)

dt_pred = dt_model.predict(X_test)

print(confusion_matrix(y_test,dt_pred))

print(classification_report(y_test,dt_pred))


#Random Forest Classification
from sklearn.ensemble import RandomForestClassifier
rf= RandomForestClassifier(n_estimators=500)
rf.fit(X_train,y_train)
rf_pre=rf.predict(X_test)
print(confusion_matrix(y_test,rf_pre))
print(classification_report(y_test,rf_pre))


#GBoosts Classifier
from xgboost import XGBClassifier
xgboost = XGBClassifier(n_estimators=1000)
xgboost.fit(X_train,y_train)

xg_pred = xgboost.predict(X_test)
print(confusion_matrix(y_test,xg_pred))

print(classification_report(y_test,xg_pred))



test = pd.read_csv('/content/drive/MyDrive/Datasets/Titanic classification/test.csv')
sns.heatmap(test.isnull())
test.drop('Cabin',axis=1,inplace=True)
test['Fare'].fillna(test['Fare'].median(), inplace=True)
test.info()
test.head()
test['Age'] = test[['Age','Pclass']].apply(impute_age,axis=1)

sex_test = pd.get_dummies(test['Sex'],drop_first=True)
embark_test= pd.get_dummies(test['Embarked'],drop_first=True)

test.drop(['Sex','Embarked','Name','Ticket'],axis=1,inplace=True)
test = pd.concat([test,sex_test,embark_test],axis=1)

test.head()
train.head()


#END
